[settings]
  id = "test.pipeline.mixer"
  lines = 8
  run = true
  buffer = 5
  log_level = "info"

[vars]
  statsmode = "shared"

[[keykeepers]]
  [keykeepers.self]
    alias = "self"

[[lookups]]
  [lookups.sql]
    alias = "posts"
    driver = "pgx"
    dsn = "postgres://postgres:pguser@localhost:5432/postgres"
    mode = "vertical"
    key_column = "param_name"
    interval = "10s"
    tls_enable = true
    [lookups.sql.on_update]
      query = 'SELECT * FROM SETTINGS_TABLE;'

[[inputs]]
  [inputs.cronjob]
    location = "UTC"
    # this job is used to create table partitions
    [[inputs.cronjob.jobs]]
      name = "partition.create"
      schedule = "@every 1s"
      force = true

[[processors]]
  [processors.through]
#    sleep = "5s"


[[processors]]
  [processors.starlark]
    log_level = "debug"
    code = '''
load("time.star", "time")
load("date.star", "date")
load("yaml.star", "yaml")
load("fs.star",   "fs")

def process(event):
    events = []

    for i in range(3):
        t = time.now() + time.hour * 24 * i
        e = newEvent("expeditions_" + t.format("2006_01_02"))
        e.setField("weekday", date.weekday_of(t))
        e.setField("month", date.month_of(t))
        e.setField("c", 1)

        events.append(e)

    return events
    '''



[[processors]]
  [processors.mixer]

[[processors]]
  [processors.through]

[[processors]]
  [processors.lookup]
    lookup = "posts"
    [processors.lookup.fields]
      posted = "currency.value"

[[outputs]]
  [outputs.log]
    level = "info"
    [outputs.log.serializer]
      type = "json"
      data_only = false
    [outputs.log.filters.glob]
      routing_key = [ "expeditions_*" ]
