[settings]
  id = "test.pipeline.cronjob"
  lines = 1
  run = true
  buffer = 1_000

[vars]
  log_level = "info"

[[keykeepers]]
  [keykeepers.self]
    alias = "self"

[[inputs]]
  [inputs.cronjob]
    location = "UTC"
    # this job is used to create table partitions
    [[inputs.cronjob.jobs]]
      name = "partition.create"
      schedule = "@every 30s"
      force = true
    # this job generates healthcheck
    [[inputs.cronjob.jobs]]
      name = "@{self:settings.id}"
      schedule = "@every 30s"
      force = true

[[processors]]
  [processors.starlark]
    code = '''
load("time.star", "time")
load("yaml.star", "yaml")
load("fs.star",   "fs")

taskfile = yaml.loads(fs.readFile("Taskfile.yaml"))

def process(event):
    events = []

    for i in range(6):
      t = time.now() + time.hour * 24 * i
      e = newEvent("expeditions_" + t.format("2006_01_02"))
      e.setField("taskfile", taskfile["tasks"]["all"]["cmds"])
      events.append(e)

    return events
    '''
  [processors.starlark.filters.glob]
    routing_key = [ "cronjob.partition.create" ]

[[processors]]
  [processors.log]
    level = "@{self:vars.log_level}"
    [processors.log.serializer]
      type = "json"
      data_only = false

[[outputs]]
  [outputs.log]
    level = "info"
    [outputs.log.serializer]
      type = "json"
      data_only = false
  [outputs.log.filters.glob]
    routing_key = [ "cronjob.healthcheck.notify" ]
